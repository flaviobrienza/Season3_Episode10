{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Challenge using LazyPredict  \n",
    "\n",
    "Kaggle Playground Challenge Season 3 Episode 10.   \n",
    "\n",
    "In this notebook I want to try for the first time LazyPredict and CalibratedClassifierCV."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "matplotlib.rcParams['font.size'] = 14\n",
    "matplotlib.rcParams['figure.figsize'] = (15, 5)\n",
    "matplotlib.rcParams['figure.facecolor'] = '#00000000'\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "import opendatasets as od"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \".\\playground-series-s3e10\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "od.download('https://www.kaggle.com/competitions/playground-series-s3e10/data?select=train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \".\\pulsar-classification-for-class-prediction\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "od.download('https://www.kaggle.com/datasets/brsdincer/pulsar-classification-for-class-prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = './playground-series-s3e10/'\n",
    "\n",
    "train = pd.read_csv(url + 'train.csv').drop(columns='id')\n",
    "test = pd.read_csv(url + 'test.csv').drop(columns='id')\n",
    "submission = pd.read_csv(url + 'sample_submission.csv')\n",
    "\n",
    "original = pd.read_csv('./pulsar-classification-for-class-prediction/Pulsar.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 117564 entries, 0 to 117563\n",
      "Data columns (total 9 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   Mean_Integrated       117564 non-null  float64\n",
      " 1   SD                    117564 non-null  float64\n",
      " 2   EK                    117564 non-null  float64\n",
      " 3   Skewness              117564 non-null  float64\n",
      " 4   Mean_DMSNR_Curve      117564 non-null  float64\n",
      " 5   SD_DMSNR_Curve        117564 non-null  float64\n",
      " 6   EK_DMSNR_Curve        117564 non-null  float64\n",
      " 7   Skewness_DMSNR_Curve  117564 non-null  float64\n",
      " 8   Class                 117564 non-null  int64  \n",
      "dtypes: float64(8), int64(1)\n",
      "memory usage: 8.1 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 78377 entries, 0 to 78376\n",
      "Data columns (total 8 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Mean_Integrated       78377 non-null  float64\n",
      " 1   SD                    78377 non-null  float64\n",
      " 2   EK                    78377 non-null  float64\n",
      " 3   Skewness              78377 non-null  float64\n",
      " 4   Mean_DMSNR_Curve      78377 non-null  float64\n",
      " 5   SD_DMSNR_Curve        78377 non-null  float64\n",
      " 6   EK_DMSNR_Curve        78377 non-null  float64\n",
      " 7   Skewness_DMSNR_Curve  78377 non-null  float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 4.8 MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17898 entries, 0 to 17897\n",
      "Data columns (total 9 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Mean_Integrated       17898 non-null  float64\n",
      " 1   SD                    17898 non-null  float64\n",
      " 2   EK                    17898 non-null  float64\n",
      " 3   Skewness              17898 non-null  float64\n",
      " 4   Mean_DMSNR_Curve      17898 non-null  float64\n",
      " 5   SD_DMSNR_Curve        17898 non-null  float64\n",
      " 6   EK_DMSNR_Curve        17898 non-null  float64\n",
      " 7   Skewness_DMSNR_Curve  17898 non-null  float64\n",
      " 8   Class                 17898 non-null  int64  \n",
      "dtypes: float64(8), int64(1)\n",
      "memory usage: 1.2 MB\n"
     ]
    }
   ],
   "source": [
    "original.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train, original])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Mean_Integrated', 'SD', 'EK', 'Skewness', 'Mean_DMSNR_Curve',\n",
       "       'SD_DMSNR_Curve', 'EK_DMSNR_Curve', 'Skewness_DMSNR_Curve', 'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Features  \n",
    "\n",
    "These are features suggested by ChatGPT, by the way adding them does not seem to improve the performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Range of the Integrated Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['int_prof_range'] = max(train.Mean_Integrated) - min(train.Mean_Integrated)\n",
    "test['int_prof_range'] = max(test.Mean_Integrated) - min(test.Mean_Integrated)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficient of Variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['coefficient_of_variation'] = train.SD / train.Mean_Integrated \n",
    "test['coefficient_of_variation'] = test.SD / test.Mean_Integrated "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal to Noise Ratio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['signal_to_noise_ratio'] = train.Mean_Integrated / train.SD\n",
    "test['signal_to_noise_ratio'] = test.Mean_Integrated / test.SD"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing in X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns='Class')\n",
    "y = train.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    122856\n",
       "1     12606\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling  \n",
    "\n",
    "After some trials the best scaler seems to be the RobustScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = X.select_dtypes(np.number).columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler().fit(X[numerical_cols])\n",
    "\n",
    "X[numerical_cols] = scaler.transform(X[numerical_cols])\n",
    "test[numerical_cols] = scaler.transform(test[numerical_cols])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting  \n",
    "\n",
    "It is necessary to create a validation set in this case since in the test set the target variable is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using LazyPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lazypredict\n",
    "from lazypredict.Supervised import LazyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4/29 [00:29<03:09,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB model failed to execute\n",
      "Negative values in data passed to CategoricalNB (input X)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 14/29 [00:38<00:18,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelPropagation model failed to execute\n",
      "Unable to allocate 87.5 GiB for an array with shape (108369, 108369) and data type float64\n",
      "LabelSpreading model failed to execute\n",
      "Unable to allocate 87.5 GiB for an array with shape (108369, 108369) and data type float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 19/29 [00:42<00:07,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NuSVC model failed to execute\n",
      "specified nu is infeasible\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 26/29 [01:27<00:22,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StackingClassifier model failed to execute\n",
      "StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [01:32<00:00,  3.20s/it]\n"
     ]
    }
   ],
   "source": [
    "reg = LazyClassifier(verbose=0, ignore_warnings=False, custom_metric=None)\n",
    "\n",
    "models, predictions = reg.fit(X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is sorted by the ROC AUC score, since it is the one used in the challenge evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "      <td>4.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "      <td>22.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "      <td>4.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.99</td>\n",
       "      <td>5.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.99</td>\n",
       "      <td>8.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.99</td>\n",
       "      <td>22.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.99</td>\n",
       "      <td>15.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.99</td>\n",
       "      <td>4.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeClassifier</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NearestCentroid</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
       "Model                                                                           \n",
       "LGBMClassifier                     0.99               0.96     0.96      0.99   \n",
       "XGBClassifier                      0.99               0.96     0.96      0.99   \n",
       "BernoulliNB                        0.97               0.96     0.96      0.98   \n",
       "RandomForestClassifier             0.99               0.96     0.96      0.99   \n",
       "QuadraticDiscriminantAnalysis      0.98               0.96     0.96      0.98   \n",
       "ExtraTreesClassifier               0.99               0.96     0.96      0.99   \n",
       "KNeighborsClassifier               0.99               0.96     0.96      0.99   \n",
       "AdaBoostClassifier                 0.99               0.95     0.95      0.99   \n",
       "BaggingClassifier                  0.99               0.95     0.95      0.99   \n",
       "SVC                                0.99               0.95     0.95      0.99   \n",
       "SGDClassifier                      0.99               0.95     0.95      0.99   \n",
       "CalibratedClassifierCV             0.99               0.95     0.95      0.99   \n",
       "LogisticRegression                 0.99               0.95     0.95      0.99   \n",
       "DecisionTreeClassifier             0.98               0.95     0.95      0.98   \n",
       "LinearSVC                          0.99               0.95     0.95      0.99   \n",
       "GaussianNB                         0.96               0.94     0.94      0.96   \n",
       "ExtraTreeClassifier                0.98               0.94     0.94      0.98   \n",
       "PassiveAggressiveClassifier        0.98               0.94     0.94      0.98   \n",
       "Perceptron                         0.98               0.93     0.93      0.98   \n",
       "LinearDiscriminantAnalysis         0.99               0.93     0.93      0.99   \n",
       "NearestCentroid                    0.98               0.92     0.92      0.98   \n",
       "RidgeClassifier                    0.98               0.91     0.91      0.98   \n",
       "RidgeClassifierCV                  0.98               0.91     0.91      0.98   \n",
       "DummyClassifier                    0.91               0.50     0.50      0.86   \n",
       "\n",
       "                               Time Taken  \n",
       "Model                                      \n",
       "LGBMClassifier                       0.45  \n",
       "XGBClassifier                        4.42  \n",
       "BernoulliNB                          0.09  \n",
       "RandomForestClassifier              22.33  \n",
       "QuadraticDiscriminantAnalysis        0.11  \n",
       "ExtraTreesClassifier                 4.87  \n",
       "KNeighborsClassifier                 1.70  \n",
       "AdaBoostClassifier                   5.96  \n",
       "BaggingClassifier                    8.31  \n",
       "SVC                                 22.07  \n",
       "SGDClassifier                        0.13  \n",
       "CalibratedClassifierCV              15.31  \n",
       "LogisticRegression                   0.30  \n",
       "DecisionTreeClassifier               1.43  \n",
       "LinearSVC                            4.22  \n",
       "GaussianNB                           0.09  \n",
       "ExtraTreeClassifier                  0.10  \n",
       "PassiveAggressiveClassifier          0.11  \n",
       "Perceptron                           0.11  \n",
       "LinearDiscriminantAnalysis           0.16  \n",
       "NearestCentroid                      0.07  \n",
       "RidgeClassifier                      0.08  \n",
       "RidgeClassifierCV                    0.13  \n",
       "DummyClassifier                      0.07  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.sort_values('ROC AUC', ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some hyperparams ranges are taken from: https://medium.com/broadhorizon-cmotions/hyperparameter-tuning-for-hyperaccurate-xgboost-model-d6e6b8650a11  \n",
    "\n",
    "This is only one of the run made, it is provided as an example.  \n",
    "\n",
    "I have decided to fit the RandomizedSearchCV on the entire training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_reg_lambda</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_min_child_weight</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75.452836</td>\n",
       "      <td>4.589257</td>\n",
       "      <td>0.218348</td>\n",
       "      <td>0.016156</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1500</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'subsample': 0.6, 'reg_lambda': 1.5, 'n_estim...</td>\n",
       "      <td>0.995351</td>\n",
       "      <td>0.996883</td>\n",
       "      <td>0.995511</td>\n",
       "      <td>0.996081</td>\n",
       "      <td>0.983970</td>\n",
       "      <td>0.993559</td>\n",
       "      <td>0.004825</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.870390</td>\n",
       "      <td>0.136100</td>\n",
       "      <td>0.071134</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.85</td>\n",
       "      <td>{'subsample': 0.9, 'reg_lambda': 1, 'n_estimat...</td>\n",
       "      <td>0.993020</td>\n",
       "      <td>0.995048</td>\n",
       "      <td>0.994067</td>\n",
       "      <td>0.994451</td>\n",
       "      <td>0.981519</td>\n",
       "      <td>0.991621</td>\n",
       "      <td>0.005094</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>113.248182</td>\n",
       "      <td>5.966960</td>\n",
       "      <td>0.435441</td>\n",
       "      <td>0.008272</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'subsample': 0.8, 'reg_lambda': 0, 'n_estimat...</td>\n",
       "      <td>0.992911</td>\n",
       "      <td>0.995261</td>\n",
       "      <td>0.993452</td>\n",
       "      <td>0.994193</td>\n",
       "      <td>0.981556</td>\n",
       "      <td>0.991474</td>\n",
       "      <td>0.005021</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "1      75.452836      4.589257         0.218348        0.016156   \n",
       "4      17.870390      0.136100         0.071134        0.000813   \n",
       "0     113.248182      5.966960         0.435441        0.008272   \n",
       "\n",
       "  param_subsample param_reg_lambda param_n_estimators param_min_child_weight  \\\n",
       "1             0.6              1.5               1500                      9   \n",
       "4             0.9                1                300                      8   \n",
       "0             0.8                0               1500                     10   \n",
       "\n",
       "  param_max_depth param_learning_rate  ... param_colsample_bytree  \\\n",
       "1               5                0.01  ...                    0.8   \n",
       "4               8                 0.3  ...                   0.85   \n",
       "0               9                 0.1  ...                    0.6   \n",
       "\n",
       "                                              params split0_test_score  \\\n",
       "1  {'subsample': 0.6, 'reg_lambda': 1.5, 'n_estim...          0.995351   \n",
       "4  {'subsample': 0.9, 'reg_lambda': 1, 'n_estimat...          0.993020   \n",
       "0  {'subsample': 0.8, 'reg_lambda': 0, 'n_estimat...          0.992911   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "1           0.996883           0.995511           0.996081           0.983970   \n",
       "4           0.995048           0.994067           0.994451           0.981519   \n",
       "0           0.995261           0.993452           0.994193           0.981556   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "1         0.993559        0.004825                1  \n",
       "4         0.991621        0.005094                2  \n",
       "0         0.991474        0.005021                3  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification = RandomizedSearchCV(XGBClassifier(n_jobs=-1, random_state=42), {\n",
    "    'max_depth': [1,2,3,4,5,6,7,8,9,10],\n",
    "    'learning_rate': [.001, .005, .01, .05, .1, .2, .3],\n",
    "    'n_estimators': [300, 500, 1000, 1500],\n",
    "    'min_child_weight': [1,2,3,4,5,6,7,8,9,10],\n",
    "    'subsample': [.4, .5, .6, .7, .8, .9, 1],\n",
    "    'colsample_bytree': [.4, .5, .6, .7, .75, .77, .79 ,.8, .85],\n",
    "    'gamma': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    'reg_lambda':[0, 0.5, 1, 1.5, 2, 3, 4.5]\n",
    "}, cv=5, return_train_score=False, scoring='roc_auc', n_iter=5)\n",
    "\n",
    "classification.fit(X,y)\n",
    "\n",
    "pd.DataFrame(classification.cv_results_).sort_values('rank_test_score').head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.6,\n",
       " 'reg_lambda': 1.5,\n",
       " 'n_estimators': 1500,\n",
       " 'min_child_weight': 9,\n",
       " 'max_depth': 5,\n",
       " 'learning_rate': 0.01,\n",
       " 'gamma': 0.0,\n",
       " 'colsample_bytree': 0.8}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing the model with its best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(n_jobs=-1, n_estimators=1500, max_depth=5, subsample=0.6, gamma=0, colsample_bytree=0.8, learning_rate=0.01,\n",
    "                      reg_lambda=1.5, min_child_weight=9 ,random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibrating Probabilities  \n",
    "\n",
    "It can lead to a better score.  \n",
    "The Isotonic one provided the best performance in this case.  \n",
    "\n",
    "Tutorial used for CalibratedClassifierCV: https://machinelearningmastery.com/calibrated-classification-model-in-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CalibratedClassifierCV(base_estimator=XGBClassifier(base_score=None,\n",
       "                                                    booster=None,\n",
       "                                                    callbacks=None,\n",
       "                                                    colsample_bylevel=None,\n",
       "                                                    colsample_bynode=None,\n",
       "                                                    colsample_bytree=0.5,\n",
       "                                                    early_stopping_rounds=None,\n",
       "                                                    enable_categorical=False,\n",
       "                                                    eval_metric=None, gamma=0,\n",
       "                                                    gpu_id=None,\n",
       "                                                    grow_policy=None,\n",
       "                                                    importance_type=None,\n",
       "                                                    interaction_constraints=None,\n",
       "                                                    learning_rate=0.2,\n",
       "                                                    max_bin=None,\n",
       "                                                    max_cat_to_onehot=None,\n",
       "                                                    max_delta_step=None,\n",
       "                                                    max_depth=2,\n",
       "                                                    max_leaves=None,\n",
       "                                                    min_child_weight=2,\n",
       "                                                    missing=nan,\n",
       "                                                    monotone_constraints=None,\n",
       "                                                    n_estimators=500, n_jobs=-1,\n",
       "                                                    num_parallel_tree=None,\n",
       "                                                    predictor=None,\n",
       "                                                    random_state=42,\n",
       "                                                    reg_alpha=None,\n",
       "                                                    reg_lambda=4.5, ...),\n",
       "                       cv=5, method='isotonic')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calibrated_model = CalibratedClassifierCV(model, method='isotonic', cv=5)\n",
    "\n",
    "calibrated_model.fit(X,y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = calibrated_model.predict_proba(test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Class'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('fifteenth_attempt.csv', index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LazyPredict has been very helpful to find the best model to use in this case, even though almost all of them provide the same performance.  \n",
    "\n",
    "Personally, I have decided to use XGBClassifier since it is the one I know better.  \n",
    "\n",
    "It is important to first discover the best model and then tuning the hyperparameters. In this case I wanted to train the RandomizedSearchCV on the entire dataset  \n",
    "in order to consider all the training data provided by Kaggle. The results could be quite different, but the suggestion provided by LazyPredict is still right.  \n",
    "\n",
    "So far the best result was obtained without calibrating the probabilities and without adding new features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
